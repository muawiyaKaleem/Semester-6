{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **By using Keras as deep learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the dataset from titanic.csv and make a Dataframe\n",
    "\n",
    "data = pd.DataFrame(pd.read_csv(\"titanic.csv\"))\n",
    "data = data.drop(columns=[\"Name\",\"Ticket\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>147</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>247 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  Sex        Age  SibSp  Parch     Fare  \\\n",
       "1              2         1       1    0  38.000000      1      0  71.2833   \n",
       "5              6         0       3    1  29.699118      0      0   8.4583   \n",
       "9             10         1       2    0  14.000000      1      0  30.0708   \n",
       "16            17         0       3    1   2.000000      4      1  29.1250   \n",
       "19            20         1       3    0  29.699118      0      0   7.2250   \n",
       "..           ...       ...     ...  ...        ...    ...    ...      ...   \n",
       "875          876         1       3    0  15.000000      0      0   7.2250   \n",
       "879          880         1       1    0  56.000000      0      1  83.1583   \n",
       "885          886         0       3    0  39.000000      0      5  29.1250   \n",
       "889          890         1       1    1  26.000000      0      0  30.0000   \n",
       "890          891         0       3    1  32.000000      0      0   7.7500   \n",
       "\n",
       "     Cabin  Embarked  \n",
       "1       81         0  \n",
       "5      147         1  \n",
       "9      147         0  \n",
       "16     147         1  \n",
       "19     147         0  \n",
       "..     ...       ...  \n",
       "875    147         0  \n",
       "879     70         0  \n",
       "885    147         1  \n",
       "889     60         0  \n",
       "890    147         1  \n",
       "\n",
       "[247 rows x 10 columns]"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "encorder = LabelEncoder()                                                   # Label Encorder to encode the columns like 1 for male and 0 for female\n",
    "\n",
    "data[\"Sex\"] = encorder.fit_transform(data[\"Sex\"])\n",
    "data[\"Embarked\"] = encorder.fit_transform(data[\"Embarked\"])\n",
    "data[\"Cabin\"] = encorder.fit_transform(data[\"Cabin\"])\n",
    "columns = [\"Cabin\", \"Fare\", \"Age\"]\n",
    "\n",
    "for i in columns:                                                           # Cleaning the NaN values from the dataframe\n",
    "    data[i] = pd.to_numeric(data[i], errors=\"coerce\")\n",
    "    mean_value = data[i].mean()\n",
    "    data[i] = data[i].fillna(mean_value)\n",
    "\n",
    "data = data[data[\"Embarked\"] != 2]                                          # There is 3 group in this column so i remove one classifier from the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Spliting the data into X and y**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[[\"Embarked\",\"Survived\"]]                                               # Taking two features in y embarced and survived\n",
    "X = data.drop(columns=[\"Survived\",\"Embarked\"])                                  # Rest of all columns store in X\n",
    "\n",
    "scaler = StandardScaler()                                                       # scaler use to set all the values on same scale\n",
    "\n",
    "x_scale = scaler.fit_transform(X)                                               # Scaling\n",
    "y_scale = scaler.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()                                                            # Model use for deep learning alogrithms\n",
    "\n",
    "model.add(Dense(16,input_dim = X.shape[1],activation='relu'))                   # Add input layer(input_dim is no of features)\n",
    "\n",
    "model.add(Dense(32, activation='relu'))                                         # Add hidden layer with activation function\n",
    "\n",
    "model.add(Dense(2,activation='sigmoid'))                                        # use 2 neuron represent the number of target values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy']) # Compile the model, means give model the function in which it put and check the values + deal with errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 4ms/step - loss: 0.6390 - accuracy: 0.3522\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.5500 - accuracy: 0.4656\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.4693 - accuracy: 0.5142\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.5385\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.5749\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.2432 - accuracy: 0.6032\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 4ms/step - loss: 0.1744 - accuracy: 0.6316\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 6ms/step - loss: 0.0996 - accuracy: 0.6721\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: 0.0272 - accuracy: 0.6883\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 5ms/step - loss: -0.0477 - accuracy: 0.6842\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 120.3454 - accuracy: 0.6235\n",
      "Accuracy:  62.0 %\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_scale,y_scale,epochs=10)                                            # Then fit the values into the model\n",
    "\n",
    "loss,accuracy_neural = model.evaluate(X,y)                                      # Evaluate mean i think it works like predictions functions we use in scikit\n",
    "\n",
    "print(f'Accuracy: ',round(accuracy_neural*100,0),'%')                           # printing the accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Do by using scikit-learn**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **by using the same data from above after droping and removing null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Train the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.drop(columns=[\"Embarked\"])                                                                # In y take only one column as target because in scikit we take only 1 feature as y\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=0,test_size=0.2)              # Testing and spliting the data into 80% and 20%\n",
    "\n",
    "X_train_scale = scaler.fit_transform(X_train)                                                   # Again scaling for scikit data to do them on same scale\n",
    "X_test_scale = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 70.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dr-pc/anaconda3/lib/python3.11/site-packages/sklearn/utils/validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "perceptron = Perceptron(eta0=0.1,max_iter=100)                                                 # Model used is name as Perceptron (also NN model)\n",
    "\n",
    "perceptron.fit(X_train_scale,y_train)                                                          # Fit in the values\n",
    "predictions = perceptron.predict(X_test_scale)\n",
    "\n",
    "accuracy_scikit = accuracy_score(y_test,predictions)                                           # Built in function to check the accuracy of the Perceptron\n",
    "\n",
    "print(f'Accuracy: {round(accuracy_scikit*100,0)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                                                                # Library used for making graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models_name = [\"Keras_Model\",\"Scikit_Model\"]                                                    # Models name store in list to give as a parameter to graph function\n",
    "\n",
    "accuracies = [accuracy_neural,accuracy_scikit]                                                  # Do same with both of the accuracies of the models\n",
    "\n",
    "plt.bar(models_name,accuracies,color='skyblue')                                                 # Function used to make a bar graph\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
